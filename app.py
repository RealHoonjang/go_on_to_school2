import streamlit as st
import pandas as pd
import json
import os
from pathlib import Path
import plotly.graph_objects as go
import plotly.express as px
from collections import defaultdict
import numpy as np

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì²´ìœ¡ ì§„ë¡œ ì§„í•™ í”„ë¡œê·¸ë¨ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸƒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ë“¤
@st.cache_data
def load_json_data(file_path):
    """JSON íŒŒì¼ ë¡œë“œ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {file_path} - {str(e)}")
        return None

@st.cache_data
def load_csv_data(file_path):
    """CSV íŒŒì¼ ë¡œë“œ"""
    try:
        return pd.read_csv(file_path, encoding='utf-8')
    except Exception as e:
        st.error(f"CSV íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {file_path} - {str(e)}")
        return None

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_DIR = Path("data")
JINRO_DIR = Path("jinro")
LOGO_DIR = Path("logo")

# ì¢…ëª© ë§¤í•‘
EVENT_MAPPING = {
    'seoul': {
        'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸°',
        'sit_up': 'ì•‰ì•„ìœ—ëª¸ì•ìœ¼ë¡œêµ½íˆê¸°',
        '10m_dash': '10mì™•ë³µë‹¬ë¦¬ê¸°',
        'vertical_jump': 'ì„œì „íŠ¸ì í”„',
        '20m_dash': '20mì™•ë³µë‹¬ë¦¬ê¸°',
        'grip_strength': 'ë°°ê·¼ë ¥',
        'medicine_ball_throw': 'ë©”ë””ì‹ ë³¼ë˜ì§€ê¸°'
    },
    'inchoen': {
        'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸°',
        'sit_up': 'ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°',
        '10m_dash': '10m ì™•ë³µë‹¬ë¦¬ê¸°',
        'grip_strength': 'ë°°ê·¼ë ¥',
        'medicine_ball_throw': 'ë©”ë””ì‹ ë³¼ë˜ì§€ê¸°',
        'front_bend': 'ì¢Œì „êµ´'
    },
    'jeju': {
        'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸°',
        'sit_up': 'ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°',
        '20m_dash': '20më‹¬ë¦¬ê¸°',
        'grip_strength': 'ë°°ê·¼ë ¥'
    },
    'chungnam': {
        'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸°',
        'vertical_jump': 'ì„œì „íŠ¸ì í”„',
        'grip_strength': 'ë°°ê·¼ë ¥',
        '10m_dash': '10Mì™•ë³µë‹¬ë¦¬ê¸°',
        'medicine_ball_throw': 'ë©”ë””ì‹ ë³¼ë˜ì§€ê¸°',
        'sit_up': 'ì•‰ì•„ìœ—ëª¸ì•ìœ¼ë¡œêµ½íˆê¸°'
    },
    'chungbuk': {
        'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸°',
        'grip_strength': 'ë°°ê·¼ë ¥',
        '10m_dash': '10mì™•ë³µë‹¬ë¦¬ê¸°',
        'medicine_ball_throw': 'ë©”ë””ì‹ ë³¼ë˜ì§€ê¸°',
        'sit_up': 'ì•‰ì•„ìœ—ëª¸ì•ìœ¼ë¡œêµ½íˆê¸°'
    },
    'deajeon': {
        'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸°',
        'sit_up': 'ì‹¯ì—…',
        'front_bend': 'ì•‰ì•„ìœ—ëª¸ì•ìœ¼ë¡œêµ½íˆê¸°',
        '10m_dash': '10Mì™•ë³µë‹¬ë¦¬ê¸°',
        'medicine_ball_throw': 'ë©”ë””ì‹ ë³¼ë˜ì§€ê¸°'
    },
    'kwangju': {
        '10m_dash': '10M ì™•ë³µ ê¸°ë¡',
        'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸° ê¸°ë¡',
        'grip_strength': 'ë°°ê·¼ë ¥ ê¸°ë¡',
        'front_bend': 'ì¢Œì „êµ´ ê¸°ë¡',
        'medicine_ball_throw': 'ë©”ë””ì‹ ë³¼ë˜ì§€ê¸° ê¸°ë¡'
    }
}

EVENT_DISPLAY_NAMES = {
    'standing_long_jump': 'ì œìë¦¬ë©€ë¦¬ë›°ê¸°',
    'vertical_jump': 'ì„œì „íŠ¸ì í”„',
    'grip_strength': 'ë°°ê·¼ë ¥',
    'sit_up': 'ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°',
    '10m_dash': '10m ë‹¬ë¦¬ê¸°',
    '20m_dash': '20m ë‹¬ë¦¬ê¸°',
    'long_run': 'ì˜¤ë˜ë‹¬ë¦¬ê¸°',
    'medicine_ball_throw': 'ë©”ë””ì‹ ë³¼ë˜ì§€ê¸°',
    'front_bend': 'ì•‰ì•„ìœ—ëª¸ì•ìœ¼ë¡œêµ½íˆê¸°'
}

UNIT_MAP = {
    'standing_long_jump': 'cm',
    'vertical_jump': 'cm',
    'grip_strength': 'kg',
    'sit_up': 'íšŒ',
    '10m_dash': 'ì´ˆ',
    '20m_dash': 'ì´ˆ',
    'long_run': 'ì´ˆ',
    'medicine_ball_throw': 'm',
    'front_bend': 'cm'
}

# ì§€ì—­ëª… ë§¤í•‘
REGION_NAMES = {
    'seoul': 'ì„œìš¸',
    'inchoen': 'ì¸ì²œ',
    'jeju': 'ì œì£¼',
    'chungnam': 'ì¶©ë‚¨',
    'chungbuk': 'ì¶©ë¶',
    'deajeon': 'ëŒ€ì „',
    'kwangju': 'ê´‘ì£¼'
}

def process_region_data(data, region):
    """ì§€ì—­ ë°ì´í„° ì²˜ë¦¬"""
    processed = []
    if not isinstance(data, list):
        return processed
    
    for item in data:
        if not isinstance(item, dict):
            continue
        
        processed_item = {
            'region': REGION_NAMES.get(region, region),
            'gender': item.get('ì„±ë³„', ''),
            'event': item.get('ì¢…ëª©', ''),
            'score': item.get('ê¸°ë¡', None)
        }
        
        # ê¸°ë¡ì„ ìˆ«ìë¡œ ë³€í™˜
        if processed_item['score'] is not None:
            try:
                processed_item['score'] = float(processed_item['score'])
            except (ValueError, TypeError):
                processed_item['score'] = None
        
        if processed_item['score'] is not None:
            processed.append(processed_item)
    
    return processed

@st.cache_data
def load_all_sports_data():
    """ëª¨ë“  ì§€ì—­ì˜ ì²´ìœ¡ ì‹¤ê¸° ë°ì´í„° ë¡œë“œ"""
    all_data = {}
    regions = ['seoul', 'inchoen', 'jeju', 'chungnam', 'chungbuk', 'deajeon', 'kwangju']
    
    for region in regions:
        file_path = DATA_DIR / f"{region}.json"
        if file_path.exists():
            data = load_json_data(file_path)
            if data:
                all_data[region] = process_region_data(data, region)
    
    return all_data

def get_filtered_scores(event_key, gender, all_data):
    """íŠ¹ì • ì¢…ëª©ê³¼ ì„±ë³„ì— ëŒ€í•œ ì ìˆ˜ í•„í„°ë§"""
    scores = []
    
    for region, data in all_data.items():
        event_name = EVENT_MAPPING.get(region, {}).get(event_key, '')
        if not event_name:
            continue
        
        for item in data:
            if item['event'] == event_name and item['gender'] == gender:
                if item['score'] is not None:
                    scores.append(item['score'])
    
    return sorted(scores)

def calculate_percentile(score, scores, higher_is_better=True):
    """ë°±ë¶„ìœ„ ê³„ì‚°"""
    if not scores or score is None:
        return None
    
    if higher_is_better:
        below_count = sum(1 for s in scores if s < score)
    else:
        below_count = sum(1 for s in scores if s > score)
    
    percentile = (below_count / len(scores)) * 100
    return round(percentile, 2)

def get_top_10_threshold(scores, higher_is_better=True):
    """ìƒìœ„ 10% ì„ê³„ê°’ ê³„ì‚°"""
    if not scores:
        return None
    
    sorted_scores = sorted(scores, reverse=higher_is_better)
    index = int(len(sorted_scores) * 0.1)
    if index >= len(sorted_scores):
        index = len(sorted_scores) - 1
    
    return sorted_scores[index]

def create_distribution_chart(scores, personal_score=None, top10_threshold=None, 
                              event_name="", unit="", higher_is_better=True):
    """ë¶„í¬ ì°¨íŠ¸ ìƒì„±"""
    if not scores:
        return None
    
    # íˆìŠ¤í† ê·¸ë¨ ë°ì´í„° ìƒì„±
    hist, bins = np.histogram(scores, bins=30)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    
    fig = go.Figure()
    
    # íˆìŠ¤í† ê·¸ë¨ ë°”
    fig.add_trace(go.Bar(
        x=bin_centers,
        y=hist,
        name='ë¶„í¬',
        marker_color='rgba(31, 111, 235, 0.6)',
        hovertemplate='ê¸°ë¡: %{x:.2f} ' + unit + '<br>ì¸ì›: %{y}<extra></extra>'
    ))
    
    # ê°œì¸ ê¸°ë¡ ì„ 
    if personal_score is not None:
        fig.add_vline(
            x=personal_score,
            line_dash="solid",
            line_color="#ff6384",
            line_width=3,
            annotation_text="ë‚´ ê¸°ë¡",
            annotation_position="top left",
            annotation_font_color="#ff6384",
            annotation_font_size=14
        )
    
    # ìƒìœ„ 10% ì„ 
    if top10_threshold is not None:
        fig.add_vline(
            x=top10_threshold,
            line_dash="dash",
            line_color="#2563eb",
            line_width=2,
            annotation_text="ìƒìœ„ 10%",
            annotation_position="top left",
            annotation_font_color="#2563eb",
            annotation_font_size=14
        )
    
    fig.update_layout(
        title=f"{event_name} ê¸°ë¡ ë¶„í¬",
        xaxis_title=f"ê¸°ë¡ ({unit})",
        yaxis_title="ì¸ì›",
        hovermode='x unified',
        template='plotly_white',
        height=400
    )
    
    return fig

# ë©”ì¸ ì•±
def main():
    # ì‚¬ì´ë“œë°” - ë¡œê³  ë° ë„¤ë¹„ê²Œì´ì…˜
    with st.sidebar:
        if (LOGO_DIR / "logo.jpg").exists():
            st.image(str(LOGO_DIR / "logo.jpg"), width=200)
        else:
            st.title("ğŸƒ ì²´ìœ¡ ì§„ë¡œ ì§„í•™ í”„ë¡œê·¸ë¨")
        
        st.markdown("---")
        page = st.radio(
            "ë©”ë‰´ ì„ íƒ",
            ["ğŸ“Š ì‹¤ê¸° ì„±ì  ë¶„ì„", "ğŸ“ ì§„ë¡œ ë° ìê²©ì¦ ì •ë³´"],
            label_visibility="collapsed"
        )
    
    if page == "ğŸ“Š ì‹¤ê¸° ì„±ì  ë¶„ì„":
        show_analysis_page()
    else:
        show_career_page()

def show_analysis_page():
    """ì‹¤ê¸° ì„±ì  ë¶„ì„ í˜ì´ì§€"""
    st.title("ğŸƒ ì²´ìœ¡ ì‹¤ê¸° ì„±ì  ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("7ê°œ ì‹œÂ·ë„ì˜ ì‹¤ê¸° ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë¹„êµí•˜ê³ , ë‚´ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ê²© ê°€ëŠ¥ì„±ì„ ë¹ ë¥´ê²Œ í™•ì¸í•˜ì„¸ìš”.")
    
    # ë°ì´í„° ë¡œë“œ
    all_data = load_all_sports_data()
    
    if not all_data:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # ì¢…ëª© ì„ íƒ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        event_options = {name: key for key, name in EVENT_DISPLAY_NAMES.items()}
        selected_event_name = st.selectbox(
            "ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”",
            options=list(EVENT_DISPLAY_NAMES.values()),
            key="event_select"
        )
        selected_event_key = event_options[selected_event_name]
    
    with col2:
        gender = st.selectbox("ì„±ë³„", ["ë‚¨", "ì—¬"], key="gender_select")
    
    if not selected_event_key:
        st.info("ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
    
    # í•´ë‹¹ ì¢…ëª©ì˜ ë°ì´í„° í•„í„°ë§
    scores = get_filtered_scores(selected_event_key, gender, all_data)
    
    if not scores:
        st.warning(f"{selected_event_name} ì¢…ëª©ì˜ {gender}ì„± ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í†µê³„ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ì¸ì›", f"{len(scores):,}ëª…")
    with col2:
        st.metric("í‰ê· ", f"{np.mean(scores):.2f} {UNIT_MAP[selected_event_key]}")
    with col3:
        st.metric("ì¤‘ì•™ê°’", f"{np.median(scores):.2f} {UNIT_MAP[selected_event_key]}")
    with col4:
        st.metric("í‘œì¤€í¸ì°¨", f"{np.std(scores):.2f}")
    
    st.markdown("---")
    
    # ê°œì¸ ê¸°ë¡ ì…ë ¥
    st.subheader("ğŸ“ ê°œì¸ ê¸°ë¡ ì…ë ¥")
    col1, col2 = st.columns([1, 2])
    
    with col1:
        higher_is_better = selected_event_key not in ['10m_dash', '20m_dash', 'long_run']
        unit = UNIT_MAP[selected_event_key]
        
        personal_score = st.number_input(
            f"ë‚´ ê¸°ë¡ ({unit})",
            min_value=0.0,
            value=float(np.median(scores)) if scores else 0.0,
            step=0.01 if unit in ['ì´ˆ', 'm'] else 1.0,
            key="personal_score"
        )
    
    with col2:
        if personal_score is not None and personal_score > 0:
            percentile = calculate_percentile(personal_score, scores, higher_is_better)
            top10_threshold = get_top_10_threshold(scores, higher_is_better)
            
            if percentile is not None:
                # ë°±ë¶„ìœ„ ë“±ê¸‰
                if percentile >= 90:
                    grade = "ìš°ìˆ˜"
                    grade_color = "green"
                elif percentile >= 70:
                    grade = "ì–‘í˜¸"
                    grade_color = "blue"
                elif percentile >= 50:
                    grade = "ë³´í†µ"
                    grade_color = "orange"
                else:
                    grade = "ë¯¸í¡"
                    grade_color = "red"
                
                st.metric("ë‚´ ë°±ë¶„ìœ„", f"{percentile:.1f}%", f"{grade} ({grade_color})")
                
                if top10_threshold is not None:
                    if higher_is_better:
                        diff = personal_score - top10_threshold
                        st.info(f"ìƒìœ„ 10% ê¸°ì¤€: {top10_threshold:.2f} {unit} (ì°¨ì´: {diff:+.2f} {unit})")
                    else:
                        diff = top10_threshold - personal_score
                        st.info(f"ìƒìœ„ 10% ê¸°ì¤€: {top10_threshold:.2f} {unit} (ì°¨ì´: {diff:+.2f} {unit})")
    
    st.markdown("---")
    
    # ë¶„í¬ ì°¨íŠ¸
    st.subheader("ğŸ“Š ê¸°ë¡ ë¶„í¬")
    if personal_score and personal_score > 0:
        top10_threshold = get_top_10_threshold(scores, higher_is_better)
        fig = create_distribution_chart(
            scores, 
            personal_score, 
            top10_threshold,
            selected_event_name,
            UNIT_MAP[selected_event_key],
            higher_is_better
        )
    else:
        fig = create_distribution_chart(
            scores,
            None,
            None,
            selected_event_name,
            UNIT_MAP[selected_event_key],
            higher_is_better
        )
    
    if fig:
        st.plotly_chart(fig, use_container_width=True)
    
    # ìƒì„¸ í†µê³„
    with st.expander("ğŸ“ˆ ìƒì„¸ í†µê³„ ë³´ê¸°"):
        df_stats = pd.DataFrame({
            'í†µê³„': ['ìµœì†Œê°’', '1ì‚¬ë¶„ìœ„ìˆ˜', 'ì¤‘ì•™ê°’', '3ì‚¬ë¶„ìœ„ìˆ˜', 'ìµœëŒ€ê°’', 'í‰ê· ', 'í‘œì¤€í¸ì°¨'],
            'ê°’': [
                np.min(scores),
                np.percentile(scores, 25),
                np.median(scores),
                np.percentile(scores, 75),
                np.max(scores),
                np.mean(scores),
                np.std(scores)
            ]
        })
        df_stats['ë‹¨ìœ„'] = UNIT_MAP[selected_event_key]
        st.dataframe(df_stats, use_container_width=True)

def show_career_page():
    """ì§„ë¡œ ë° ìê²©ì¦ ì •ë³´ í˜ì´ì§€"""
    st.title("ğŸ“ ì²´ìœ¡ ì§„ë¡œ ë° ìê²©ì¦ ì •ë³´")
    
    # ë°ì´í„° ë¡œë“œ
    guide_df = load_csv_data(JINRO_DIR / "Guide.csv")
    cert_df = load_csv_data(JINRO_DIR / "Certificate.csv")
    loadmap_df = load_csv_data(JINRO_DIR / "loadmap.csv")
    
    if guide_df is None or cert_df is None:
        st.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ“ í•™ê³¼ë³„ ì§„ë¡œ ì°¾ê¸°", "ğŸ“œ ìê²©ì¦ë³„ ì§ì—… ì°¾ê¸°"])
    
    with tab1:
        show_major_career_tab(guide_df, cert_df, loadmap_df)
    
    with tab2:
        show_certificate_career_tab(guide_df, cert_df)

def show_major_career_tab(guide_df, cert_df, loadmap_df):
    """í•™ê³¼ë³„ ì§„ë¡œ ì°¾ê¸° íƒ­"""
    # í•™ê³¼ ëª©ë¡
    majors = sorted(guide_df['í•™ê³¼'].dropna().unique())
    
    if not majors:
        st.warning("í•™ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    selected_major = st.selectbox("í¬ë§ í•™ê³¼", ["ì„ íƒí•˜ì„¸ìš”"] + list(majors))
    
    if selected_major == "ì„ íƒí•˜ì„¸ìš”":
        st.info("í•™ê³¼ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
    
    # í•´ë‹¹ í•™ê³¼ì˜ ì§„ë¡œ í•„í„°ë§
    major_careers = guide_df[guide_df['í•™ê³¼'] == selected_major]
    
    if major_careers.empty:
        st.warning(f"{selected_major} í•™ê³¼ì˜ ì§„ë¡œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì§„ë¡œ ì„ íƒ
    careers = sorted(major_careers['ì§„ë¡œ'].dropna().unique())
    selected_career = st.selectbox("ê´€ì‹¬ ì§ì—…", ["ì„ íƒí•˜ì„¸ìš”"] + list(careers))
    
    if selected_career == "ì„ íƒí•˜ì„¸ìš”":
        # ì§„ë¡œ ëª©ë¡ ë¯¸ë¦¬ë³´ê¸°
        st.subheader(f"ğŸ“‹ {selected_major} ì§„ë¡œ ëª©ë¡")
        preview_df = major_careers[['ì§„ë¡œ', 'í•„ìš”ìê²©ì¦', 'ì´ˆë´‰/ì—°ë´‰', 'ì£¼ìš” ì·¨ì—…ì²˜']].drop_duplicates()
        st.dataframe(preview_df, use_container_width=True)
        return
    
    # ì„ íƒí•œ ì§„ë¡œì˜ ìƒì„¸ ì •ë³´
    career_info = major_careers[major_careers['ì§„ë¡œ'] == selected_career].iloc[0]
    
    st.markdown("---")
    st.subheader(f"ğŸ’¼ {selected_career}")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("í•„ìš” ìê²©", career_info.get('í•„ìš”ìê²©ì¦', '-'))
    with col2:
        st.metric("ì˜ˆìƒ ì—°ë´‰", career_info.get('ì´ˆë´‰/ì—°ë´‰', '-'))
    with col3:
        st.metric("ì£¼ìš” ì·¨ì—…ì²˜", career_info.get('ì£¼ìš” ì·¨ì—…ì²˜', '-'))
    
    if pd.notna(career_info.get('ì¤€ë¹„ì „ëµ')):
        st.info(f"**ì¤€ë¹„ì „ëµ:** {career_info['ì¤€ë¹„ì „ëµ']}")
    
    # í•„ìš” ìê²©ì¦ ì •ë³´
    required_certs = str(career_info.get('í•„ìš”ìê²©ì¦', '')).split(',')
    if required_certs and required_certs[0]:
        st.markdown("### ğŸ“œ ì¶”ì²œ ìê²©ì¦")
        for cert_name in required_certs:
            cert_name = cert_name.strip()
            if not cert_name:
                continue
            
            # ìê²©ì¦ ì •ë³´ ì°¾ê¸°
            cert_info = cert_df[cert_df['ìê²©ì¦ëª…'].str.contains(cert_name, na=False, case=False)]
            
            if not cert_info.empty:
                cert_row = cert_info.iloc[0]
                with st.expander(f"ğŸ“„ {cert_row['ìê²©ì¦ëª…']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**ë¶„ë¥˜:** {cert_row.get('ìê²©ì¦ ë¶„ë¥˜', '-')}")
                        st.write(f"**ë°œê¸‰ê¸°ê´€:** {cert_row.get('ë°œê¸‰/ê´€ë¦¬ê¸°ê´€', '-')}")
                        st.write(f"**ì‘ì‹œìê²©:** {cert_row.get('ì‘ì‹œìê²©', '-')}")
                        st.write(f"**ì‹œí—˜ê³¼ëª©:** {cert_row.get('ì‹œí—˜ê³¼ëª©', '-')}")
                    with col2:
                        st.write(f"**ì¤€ë¹„ê¸°ê°„:** {cert_row.get('ì¤€ë¹„ê¸°ê°„', '-')}")
                        st.write(f"**ì—°ë´‰/ì²˜ìš°:** {cert_row.get('ì—°ë´‰/ì²˜ìš°', '-')}")
                        st.write(f"**ìœ íš¨ê¸°ê°„:** {cert_row.get('ìœ íš¨ê¸°ê°„', '-')}")
                        st.write(f"**ë‚œì´ë„:** {cert_row.get('ë‚œì´ë„', '-')}")
                    st.write(f"**ì£¼ìš” ì·¨ì—…ì²˜:** {cert_row.get('ì£¼ìš” ì·¨ì—…ì²˜', '-')}")
            else:
                st.write(f"ğŸ“„ {cert_name} (ìƒì„¸ ì •ë³´ ì—†ìŒ)")
    
    # ë¡œë“œë§µ ì •ë³´
    if loadmap_df is not None:
        career_loadmap = loadmap_df[loadmap_df['ì§„ë¡œëª©í‘œ'] == selected_career]
        if not career_loadmap.empty:
            st.markdown("### ğŸ—ºï¸ ì§„ë¡œ ë¡œë“œë§µ")
            for idx, row in career_loadmap.iterrows():
                with st.container():
                    st.markdown(f"#### {row.get('ë‹¨ê³„', '')}")
                    st.write(f"**êµ¬ì²´ì  ì¤€ë¹„ë‚´ìš©:** {row.get('êµ¬ì²´ì ì¤€ë¹„ë‚´ìš©', '-')}")
                    st.write(f"**ì˜ˆìƒê¸°ê°„:** {row.get('ì˜ˆìƒê¸°ê°„', '-')}")
                    if pd.notna(row.get('í•„ìˆ˜ìê²©ì¦')):
                        st.write(f"**í•„ìˆ˜ìê²©ì¦:** {row.get('í•„ìˆ˜ìê²©ì¦', '-')}")
                    st.markdown("---")

def show_certificate_career_tab(guide_df, cert_df):
    """ìê²©ì¦ë³„ ì§ì—… ì°¾ê¸° íƒ­"""
    # ìê²©ì¦ ëª©ë¡
    certificates = sorted(cert_df['ìê²©ì¦ëª…'].dropna().unique())
    
    if not certificates:
        st.warning("ìê²©ì¦ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    selected_cert = st.selectbox("ìê²©ì¦ ì„ íƒ", ["ì„ íƒí•˜ì„¸ìš”"] + list(certificates))
    
    if selected_cert == "ì„ íƒí•˜ì„¸ìš”":
        st.info("ìê²©ì¦ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
    
    # ìê²©ì¦ ì •ë³´
    cert_info = cert_df[cert_df['ìê²©ì¦ëª…'] == selected_cert].iloc[0]
    
    st.markdown("---")
    st.subheader(f"ğŸ“œ {selected_cert}")
    
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**ë¶„ë¥˜:** {cert_info.get('ìê²©ì¦ ë¶„ë¥˜', '-')}")
        st.write(f"**ë°œê¸‰ê¸°ê´€:** {cert_info.get('ë°œê¸‰/ê´€ë¦¬ê¸°ê´€', '-')}")
        st.write(f"**ì‘ì‹œìê²©:** {cert_info.get('ì‘ì‹œìê²©', '-')}")
        st.write(f"**ì‹œí—˜ê³¼ëª©:** {cert_info.get('ì‹œí—˜ê³¼ëª©', '-')}")
    with col2:
        st.write(f"**ì¤€ë¹„ê¸°ê°„:** {cert_info.get('ì¤€ë¹„ê¸°ê°„', '-')}")
        st.write(f"**ì—°ë´‰/ì²˜ìš°:** {cert_info.get('ì—°ë´‰/ì²˜ìš°', '-')}")
        st.write(f"**ìœ íš¨ê¸°ê°„:** {cert_info.get('ìœ íš¨ê¸°ê°„', '-')}")
        st.write(f"**ë‚œì´ë„:** {cert_info.get('ë‚œì´ë„', '-')}")
    
    st.write(f"**ì£¼ìš” ì·¨ì—…ì²˜:** {cert_info.get('ì£¼ìš” ì·¨ì—…ì²˜', '-')}")
    
    st.markdown("---")
    
    # í•´ë‹¹ ìê²©ì¦ì„ í•„ìš”ë¡œ í•˜ëŠ” ì§ì—… ì°¾ê¸°
    st.subheader("ğŸ’¼ ì´ ìê²©ì¦ìœ¼ë¡œ ì·¨ì—…í•  ìˆ˜ ìˆëŠ” ì§ì—…")
    
    # ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
    related_careers = guide_df[
        guide_df['í•„ìš”ìê²©ì¦'].str.contains(selected_cert, na=False, case=False)
    ]
    
    if related_careers.empty:
        st.info("í•´ë‹¹ ìê²©ì¦ì„ í•„ìš”ë¡œ í•˜ëŠ” ì§ì—… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    for idx, career_row in related_careers.iterrows():
        with st.expander(f"ğŸ’¼ {career_row['ì§„ë¡œ']} ({career_row.get('í•™ê³¼', '-')})"):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("í•„ìš” ìê²©", career_row.get('í•„ìš”ìê²©ì¦', '-'))
            with col2:
                st.metric("ì˜ˆìƒ ì—°ë´‰", career_row.get('ì´ˆë´‰/ì—°ë´‰', '-'))
            with col3:
                st.metric("ì£¼ìš” ì·¨ì—…ì²˜", career_row.get('ì£¼ìš” ì·¨ì—…ì²˜', '-'))
            
            if pd.notna(career_row.get('ì¤€ë¹„ì „ëµ')):
                st.info(f"**ì¤€ë¹„ì „ëµ:** {career_row['ì¤€ë¹„ì „ëµ']}")

if __name__ == "__main__":
    main()

